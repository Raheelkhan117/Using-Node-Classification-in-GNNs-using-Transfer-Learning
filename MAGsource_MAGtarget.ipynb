{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raheelkhan117/Using-Node-Classification-in-GNNs-using-Transfer-Learning/blob/main/MAGsource_MAGtarget.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4DphzQcz36Q",
        "outputId": "00afaecd-effb-4eac-9eb1-b97690653fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxZ8G6X-4SsV",
        "outputId": "fc56ae07-8168-456d-ee9b-a659d2b56ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm\n",
            "  Cloning https://github.com/tqdm/tqdm.git (to revision devel) to /tmp/pip-install-5rxv1gd4/tqdm_d461279f517d45f984b37016fa3c84e0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tqdm/tqdm.git /tmp/pip-install-5rxv1gd4/tqdm_d461279f517d45f984b37016fa3c84e0\n",
            "  Running command git checkout -b devel --track origin/devel\n",
            "  Switched to a new branch 'devel'\n",
            "  Branch 'devel' set up to track remote branch 'devel' from 'origin'.\n",
            "  Resolved https://github.com/tqdm/tqdm.git to commit 729db6c1b52f44c01b06b2338d0688ab83b00f01\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.66.6.dev1+g729db6c-py3-none-any.whl size=78565 sha256=c7b3ede9b6d80d58ae8cbe71556df693a2ffaf901a1763b688ca3d88fca4dba2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p_tpwdr6/wheels/58/37/2e/a68b55bdff1a302c7a4a688e0237765287e22abddc0f8382b8\n",
            "Successfully built tqdm\n",
            "Installing collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "Successfully installed tqdm-4.66.6.dev1+g729db6c\n"
          ]
        }
      ],
      "source": [
        "pip install \"git+https://github.com/tqdm/tqdm.git@devel#egg=tqdm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJG-IdFW1AZc",
        "outputId": "a7673fac-65a4-46b8-a033-db678233819e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.6.dev1+g729db6c)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install ogb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDozIxQGdE7o"
      },
      "source": [
        "step 3: Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO0gXOrSdQmi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GINConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout=0.5):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels)) # input layer\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels)) # hidden layers\n",
        "\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels)) # output layer\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout=0.5):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels)) # input layer\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels)) # hidden layers\n",
        "\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels)) # output layer\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout=0.5):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GATConv(in_channels, hidden_channels)) # input layer\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATConv(hidden_channels, hidden_channels)) # hidden layers\n",
        "\n",
        "        self.convs.append(GATConv(hidden_channels, out_channels)) # output layer\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout=0.5):\n",
        "        super(GIN, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        # input layer\n",
        "        self.convs.append(\n",
        "            GINConv(Linear(in_channels, hidden_channels), train_eps=True)\n",
        "        )\n",
        "\n",
        "        # hidden layers\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                GINConv(Linear(hidden_channels, hidden_channels), train_eps=True)\n",
        "            )\n",
        "\n",
        "        # output layer\n",
        "        self.convs.append(\n",
        "            GINConv(Linear(hidden_channels, out_channels), train_eps=True)\n",
        "        )\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x.log_softmax(dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbCNttBvn7VS"
      },
      "source": [
        "**Testing below**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rznQedRoBq1"
      },
      "source": [
        "Loading data and split into source and target(node_year_dic issue solved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w8ecHK3FxHI",
        "outputId": "eb653d41-4b18-4dec-bd55-b3bbbee2c2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:01<00:00, 46.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2325.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2303.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/mag.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.40 GB: 100%|██████████| 413/413 [00:07<00:00, 53.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/mag.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1987.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2585.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import subgraph\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# DEVICE\n",
        "# ---------------------------------------------------\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# ---------------------------------------------------\n",
        "# Data\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# LOAD Arxiv\n",
        "arxiv_dataset = PygNodePropPredDataset(name='ogbn-arxiv')\n",
        "arxiv_data = arxiv_dataset[0]\n",
        "\n",
        "arxiv_data = T.ToSparseTensor()(arxiv_data)\n",
        "##arxiv_data.adj_t = arxiv_data.adj_t.to_symmetric()\n",
        "arxiv_data = arxiv_data.to(device)\n",
        "\n",
        "arxiv_split_idx = arxiv_dataset.get_idx_split()\n",
        "arxiv_evaluator = Evaluator(name='ogbn-arxiv')\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# LOAD MAG\n",
        "dataset = PygNodePropPredDataset(name=\"ogbn-mag\")\n",
        "rel_data = dataset[0]\n",
        "#print(dir(rel_data))\n",
        "#print(rel_data)\n",
        "\n",
        "\n",
        "\n",
        "data = Data(\n",
        "    x=rel_data.x_dict['paper'],\n",
        "    edge_index=rel_data.edge_index_dict[('paper', 'cites', 'paper')],\n",
        "    y=rel_data.y_dict['paper']\n",
        ").to(device)\n",
        "\n",
        "# SPLIT INTO SOURCE & TARGET SET\n",
        "years = rel_data.node_year['paper'].unique()\n",
        "source_years = years[:5]\n",
        "target_years = years[5:]\n",
        "\n",
        "source_nodes = torch.cat([\n",
        "                    torch.where(rel_data.node_year['paper'] == year)[0]\n",
        "                    for year in source_years\n",
        "                ])\n",
        "\n",
        "target_nodes = torch.cat([\n",
        "                    torch.where(rel_data.node_year['paper'] == year)[0]\n",
        "                    for year in target_years\n",
        "                ])\n",
        "\n",
        "source_nodes, _ = source_nodes.sort()\n",
        "target_nodes, _ = target_nodes.sort()\n",
        "\n",
        "source_edge_index, _ = subgraph(source_nodes, data.edge_index, relabel_nodes=True)\n",
        "target_edge_index, _ = subgraph(target_nodes, data.edge_index, relabel_nodes=True)\n",
        "\n",
        "source_data = Data(\n",
        "                x=rel_data.x_dict['paper'][source_nodes],\n",
        "                edge_index=source_edge_index,\n",
        "                y=rel_data.y_dict['paper'][source_nodes]\n",
        "            )\n",
        "\n",
        "target_data = Data(\n",
        "                x=rel_data.x_dict['paper'][target_nodes],\n",
        "                edge_index=target_edge_index,\n",
        "                y=rel_data.y_dict['paper'][target_nodes]\n",
        "            )\n",
        "\n",
        "data = target_data.to(device) # Train on Target split\n",
        "\n",
        "# MAG EVALUATOR\n",
        "evaluator = Evaluator(name=\"ogbn-mag\")\n",
        "# ---------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n405aKDQrJj_"
      },
      "source": [
        "define training and **pretraining model for MAG and Arxiv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0bwFqflqjin"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GINConv\n",
        "from models import *\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def train(model, optimiser, data):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    try:\n",
        "        out = model(data.x, data.adj_t)\n",
        "    except:\n",
        "        out = model(data.x, data.edge_index)\n",
        "\n",
        "    loss = F.nll_loss(out, data.y.squeeze(1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    # EVAL\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "    acc = evaluator.eval({\n",
        "            'y_true': data.y,\n",
        "            'y_pred': y_pred,\n",
        "        })['acc']\n",
        "\n",
        "    return loss.item(), acc\n",
        "\n",
        "\n",
        "def pretrain_mag_source(model, optimiser, data, model_name, epochs=1000):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # TRAIN\n",
        "        model.train()\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.nll_loss(out, data.y.squeeze(1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        # EVAL\n",
        "        y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "        acc = evaluator.eval({\n",
        "                'y_true': data.y,\n",
        "                'y_pred': y_pred,\n",
        "            })['acc']\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), 'source/{}_mag_source.pth'.format(model_name))\n",
        "\n",
        "    return best_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uXdejHwryO2"
      },
      "source": [
        "pretraining on source split MAG **GCN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzSAnk9XnekK",
        "outputId": "9c11c152-612e-4804-a1b2-70458c7c7658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretraining model on MAG Source split\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:50<00:00, 55.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.00556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PRETRAIN ON SOURCE SPLIT\n",
        "from models import *\n",
        "\n",
        "model = GCN(\n",
        "        in_channels=data.num_features,\n",
        "        hidden_channels=256,\n",
        "        out_channels=dataset.num_classes,\n",
        "        num_layers=3\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "model.reset_parameters()\n",
        "source_optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print('Pretraining model on MAG Source split')\n",
        "best_acc = pretrain_mag_source(model, source_optimiser, source_data.to(device), \"GCN\")\n",
        "print('Best accuracy: {:.3}'.format(best_acc))\n",
        "model.load_state_dict(\n",
        "        torch.load( '/content/source/{}_mag_source.pth'.format(\"GCN\") )\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SxXaKw9kdNH"
      },
      "source": [
        "**Training on Target MAG using Pretrained source MAG(Fine Tuning)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmmI-p05OCLm",
        "outputId": "02fdc58f-adb2-4f7b-f888-4ab5fda1b96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on MAG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:51<00:51, 51.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Train Loss: 5.885, Train Acc: 0.008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:37<00:00, 48.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Train Loss: 5.810, Train Acc: 0.017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------\n",
        "    # MODEL\n",
        "    # ---------------------------------------------------\n",
        "    # USE MAG MODEL\n",
        "model = GCN(\n",
        "        in_channels=data.num_features,\n",
        "        hidden_channels=253,\n",
        "        out_channels=dataset.num_classes,\n",
        "        num_layers=3\n",
        "    ).to(device)\n",
        "\n",
        "#MAG TARGET TRAINING\n",
        "print('Training on MAG')\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(2)):\n",
        "  train_loss, acc = train(model, optimiser, data)\n",
        "  print('Epoch: {:03d}, Train Loss: {:.3f}, Train Acc: {:.3f}'.format(epoch, train_loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4W1rVKKHVZb"
      },
      "source": [
        "**Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLjv2BQWH8bK"
      },
      "source": [
        "step 1: split target into train test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvValEoKGA9X",
        "outputId": "f17953f9-0945-4999-8ca7-2dbca469be8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train indices: 267032\n",
            "Validation indices: 33379\n",
            "Test indices: 33380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-6283a01e7119>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_indices = torch.tensor(train_indices, dtype=torch.long).to(device)\n",
            "<ipython-input-7-6283a01e7119>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_indices = torch.tensor(val_indices, dtype=torch.long).to(device)\n",
            "<ipython-input-7-6283a01e7119>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_indices = torch.tensor(test_indices, dtype=torch.long).to(device)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure that indices are in the correct format\n",
        "target_indices = torch.arange(target_data.num_nodes)\n",
        "\n",
        "# Split indices into train (80%) and temp (20%)\n",
        "train_indices, temp_indices = train_test_split(target_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
        "\n",
        "train_indices = torch.tensor(train_indices, dtype=torch.long).to(device)\n",
        "val_indices = torch.tensor(val_indices, dtype=torch.long).to(device)\n",
        "test_indices = torch.tensor(test_indices, dtype=torch.long).to(device)\n",
        "\n",
        "print(f'Train indices: {train_indices.size(0)}')\n",
        "print(f'Validation indices: {val_indices.size(0)}')\n",
        "print(f'Test indices: {test_indices.size(0)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrkJx9fRIVHO"
      },
      "source": [
        "step 2: feature extraction using the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mIGlDz_lIig5",
        "outputId": "e03b4c5e-590f-4a46-aabb-e32a7a4e0308"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.1381, Test Accuracy: 0.1385\n"
          ]
        }
      ],
      "source": [
        "def extract_features(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        features = model.convs[0](data.x, data.edge_index)\n",
        "        for conv in model.convs[1:]:\n",
        "            features = conv(features, data.edge_index)\n",
        "            features = F.relu(features)\n",
        "        return features\n",
        "\n",
        "def train_classifier(features, labels, train_idx, val_idx, test_idx, num_classes):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "##ajust iterations\n",
        "    clf = LogisticRegression(max_iter=10)\n",
        "    clf.fit(features[train_idx.cpu()], labels[train_idx.cpu()].squeeze(1))\n",
        "\n",
        "    val_preds = clf.predict(features[val_idx.cpu()])\n",
        "    test_preds = clf.predict(features[test_idx.cpu()])\n",
        "\n",
        "    val_acc = accuracy_score(labels[val_idx.cpu()].cpu(), val_preds)\n",
        "    test_acc = accuracy_score(labels[test_idx.cpu()].cpu(), test_preds)\n",
        "\n",
        "    return val_acc, test_acc\n",
        "\n",
        "# Load the pretrained model\n",
        "model.load_state_dict(torch.load('/content/source/GCN_mag_source.pth'))\n",
        "\n",
        "# Extract features from the target data using the pretrained model\n",
        "target_features = extract_features(model, target_data)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = target_data.y.max().item() + 1\n",
        "\n",
        "# Train a classifier on the extracted features\n",
        "feat_val_acc, feat_test_acc = train_classifier(target_features.cpu(), target_data.y.cpu(), train_indices, val_indices, test_indices, num_classes)\n",
        "\n",
        "print(f'Validation Accuracy: {feat_val_acc:.4f}, Test Accuracy: {feat_test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ_ZPrfNL554"
      },
      "source": [
        "**Baseline GCN training without transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvu-647FM7Et"
      },
      "outputs": [],
      "source": [
        "def train_baseline_gcn(model, optimizer, data, train_idx, val_idx, epochs=10):\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # TRAIN\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.nll_loss(out[train_idx], data.y[train_idx].squeeze(1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # EVAL\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(data.x, data.edge_index)\n",
        "            val_loss = F.nll_loss(out[val_idx], data.y[val_idx].squeeze(1)).item()\n",
        "            val_acc = (out[val_idx].argmax(dim=1) == data.y[val_idx].squeeze(1)).sum().item() / val_idx.size(0)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'baseline/gcn_baseline.pth')\n",
        "\n",
        "        print(f'Epoch {epoch:03d}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return best_val_acc\n",
        "\n",
        "def evaluate_model(model, data, test_idx):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        #will change test_acc name to base_test_acc\n",
        "        base_test_acc = (out[test_idx].argmax(dim=1) == data.y[test_idx].squeeze(1)).sum().item() / test_idx.size(0)\n",
        "    return test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "wf039sgJN041",
        "outputId": "fc2f561d-408d-44bb-e6ea-f03511aea361"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:51<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0027482e78f8>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the baseline GCN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_baseline_gcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best Validation Accuracy (Baseline GCN): {best_val_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f99b07eac6ef>\u001b[0m in \u001b[0;36mtrain_baseline_gcn\u001b[0;34m(model, optimizer, data, train_idx, val_idx, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Use predefined target MAG dataset split\n",
        "target_train_indices = train_indices.to(device)\n",
        "target_val_indices = val_indices.to(device)\n",
        "target_test_indices = test_indices.to(device)\n",
        "\n",
        "# Initialize the model, optimizer, and other parameters\n",
        "baseline_model = GCN(in_channels=128, hidden_channels=253, out_channels=num_classes, num_layers=3, dropout=0.5).to(device)\n",
        "baseline_optimizer = torch.optim.Adam(baseline_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# Train the baseline GCN model\n",
        "best_val_acc = train_baseline_gcn(baseline_model, baseline_optimizer, target_data, target_train_indices, target_val_indices, epochs=2)\n",
        "\n",
        "print(f'Best Validation Accuracy (Baseline GCN): {best_val_acc:.4f}')\n",
        "\n",
        "# Load the best model\n",
        "baseline_model.load_state_dict(torch.load('baseline/gcn_baseline.pth'))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "base_test_acc = evaluate_model(baseline_model, target_data, target_test_indices)\n",
        "\n",
        "print(f'Test Accuracy (Baseline GCN): {base_test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY80uRJ8Zsy4",
        "outputId": "de0d1f79-f78c-43d9-d760-fc763617947e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Model:\n",
            "Validation Accuracy: 0.0474, Test Accuracy: 0.0473\n",
            "Fine-Tuned Model:\n",
            "Validation Accuracy: 0.0174\n",
            "Feature Extraction Model:\n",
            "Validation Accuracy: 0.1381, Test Accuracy: 0.0473\n"
          ]
        }
      ],
      "source": [
        "# Compare the models\n",
        "print(\"Baseline Model:\")\n",
        "print(f\"Validation Accuracy: {best_val_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Fine-Tuned Model:\")\n",
        "# Assume fine_tune_val_acc and fine_tune_test_acc are obtained during fine-tuning\n",
        "#print(f\"Validation Accuracy: {fine_tune_val_acc:.4f}, Test Accuracy: {fine_tune_test_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"Feature Extraction Model:\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvEXsGADZtwZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoQ3n2nu1buvf+qhRBGc0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}